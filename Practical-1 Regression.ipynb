{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNOxXww6q9HciqSI6D8gm6D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this notebook, you will:\n","\n","1. Implement a Linear Regression model from scratch using the closed-form solution (Normal Equation).\n","2. Solve the same problem using Scikit-learn's Linear Regression module.\n","3. Extend this to a Multiple Linear Regression scenario.\n","4. Apply linear and logistic regression to a real-world datasets.\n","\n","Let's get started!"],"metadata":{"id":"gbvS6s1tP8tG"}},{"cell_type":"code","source":["# Import Libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"nV6OXa82OqpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We will first generate a synthetic dataset for a simple linear regression problem."],"metadata":{"id":"lndihVHTRvEh"}},{"cell_type":"code","source":["np.random.seed(42)  # For reproducibility\n","\n","# Simple Linear Regression Data\n","X_simple = np.random.rand(100, 1) * 10  # Feature\n","y_simple = 3 * X_simple + np.random.randn(100, 1) * 2  # Target with noise\n","\n","# Convert to DataFrame for visualization\n","df_simple = pd.DataFrame({'X': X_simple.flatten(), 'y': y_simple.flatten()})\n","df_simple.head()\n"],"metadata":{"id":"0HDZ7WBoRl4A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.scatter(X_simple, y_simple, color='blue', label='Data')\n","plt.title(\"Simple Linear Regression Data\")\n","plt.xlabel(\"X\")\n","plt.ylabel(\"y\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"pQFy7FDzR3LZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Implement Closed-Form Solution"],"metadata":{"id":"SNIp5LRBR6cv"}},{"cell_type":"code","source":["# Add bias (intercept term)\n","X_simple_bias = np.c_[np.ones((X_simple.shape[0], 1)), X_simple]\n","\n","## TODO: Compute weights\n","w_simple =\n","\n","## TODO: predict values\n","y_pred_simple_closed =\n","\n","\n","# Print weights\n","print(f\"Weights (Closed-Form Solution):\\nIntercept: {w_simple[0][0]}, Slope: {w_simple[1][0]}\")"],"metadata":{"id":"QPwuiKatR8EK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def mean_squared_error(y_true, y_pred):\n","  ## TODO: Compute the error between the predicted and true values\n","  return\n","\n","mse_simple_closed = mean_squared_error(y_simple, y_pred_simple_closed)\n","print(f\"Mean Squared Error (Closed-Form): {mse_simple_closed}\")\n"],"metadata":{"id":"9-0LO8F4SLyJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.scatter(X_simple, y_simple, color='blue', label='Actual')\n","plt.plot(X_simple, y_pred_simple_closed, color='red', label='Prediction (Closed-Form)')\n","plt.title(\"Simple Linear Regression - Closed Form\")\n","plt.xlabel(\"X\")\n","plt.ylabel(\"y\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"bwx9sf_pRoG2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Solving with scikit learn"],"metadata":{"id":"4jTGtd3HScTd"}},{"cell_type":"code","source":["## TODO: Scikit-learn Solution for Simple Linear Regression\n","\n","\n","# TODO: make predictions\n","y_pred_simple_sklearn =\n","intercept =\n","coeff =\n","\n","# Print weights\n","print(f\"Weights (Scikit-learn):\\nIntercept: {intercept}, Slope: {coeff}\")\n","\n","# Evaluate\n","mse_simple_sklearn = mean_squared_error(y_simple, y_pred_simple_sklearn)\n","print(f\"Mean Squared Error (Scikit-learn): {mse_simple_sklearn}\")"],"metadata":{"id":"_6GzWNLJSeC6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Multiple regression problem"],"metadata":{"id":"FCzafNvISzrp"}},{"cell_type":"markdown","source":["Let's try this on a multiple linear regression problem now."],"metadata":{"id":"id2VCtuYSsCU"}},{"cell_type":"code","source":["# Multiple Linear Regression Data\n","X_multi = np.random.rand(100, 2) * 10  # Two features\n","y_multi = 3 * X_multi[:, 0:1] + 2 * X_multi[:, 1:2] + np.random.randn(100, 1) * 2  # Target with noise\n","\n","df_multi = pd.DataFrame({'X1': X_multi[:, 0], 'X2': X_multi[:, 1], 'y': y_multi.flatten()})\n","\n","df_multi.head()"],"metadata":{"id":"NFLumKOJRoQz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Implement closed-form solution"],"metadata":{"id":"wg7gLKp0SyEJ"}},{"cell_type":"code","source":["# Add bias (intercept term)\n","X_multi_bias = np.c_[np.ones((X_multi.shape[0], 1)), X_multi]\n","\n","## TODO: Compute weights\n","w_multi =\n","\n","## TODO: Predicted values\n","y_pred_multi_closed =\n","\n","# Print weights\n","print(f\"Weights (Closed-Form Solution): {w_multi.flatten()}\")"],"metadata":{"id":"6NsG_1jqSxTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate Multiple Linear Regression\n","mse_multi_closed = mean_squared_error(y_multi, y_pred_multi_closed)\n","print(f\"Mean Squared Error (Closed-Form): {mse_multi_closed}\")"],"metadata":{"id":"GbfeoT-7TDWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## TODO: fit the model\n","\n","# make predictions\n","y_pred_multi_sklearn =\n","intercept =\n","coeff =\n","\n","# Print weights\n","print(f\"Weights (Scikit-learn):\\nIntercept: {intercept}, Coefficients: {coeff}\")\n","\n","# Evaluate\n","mse_multi_sklearn = mean_squared_error(y_multi, y_pred_multi_sklearn)\n","print(f\"Mean Squared Error (Scikit-learn): {mse_multi_sklearn}\")"],"metadata":{"id":"2m5bxVXKTFRy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","plt.scatter(y_multi, y_pred_multi_sklearn, alpha=0.6, edgecolors='k')\n","plt.plot([y_multi.min(), y_multi.max()], [y_multi.min(), y_multi.max()], 'r--', lw=2)\n","plt.xlabel(\"Observed Values\")\n","plt.ylabel(\"Predicted Values\")\n","plt.title(\"Observed vs. Predicted Values\")\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"Zys8TxCTz4gZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Now let's work with a real-world dataset: the New York Stock Exchange dataset.\n","\n","While we focus on this specific dataset, you can find several new datasets to apply and play around with [here](https://www.kaggle.com/datasets?tags=13405-Linear+Regression).\n"],"metadata":{"id":"IDh41wGDTXuJ"}},{"cell_type":"code","source":["! pip install kagglehub"],"metadata":{"id":"8sw-wCRrfG0E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import kagglehub\n","path = kagglehub.dataset_download(\"dgawlik/nyse\")"],"metadata":{"id":"5kftg-Dre_fl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Path to dataset files:\", path)"],"metadata":{"id":"mE_aH2WyfRTN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /root/.cache/kagglehub/datasets/dgawlik/nyse/versions/3"],"metadata":{"id":"ZbeRH_zLfV6c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n"],"metadata":{"id":"GxrcfWRDfdZv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preparing the data\n"],"metadata":{"id":"p8sCjPLdTezL"}},{"cell_type":"code","source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Load the datasets\n","prices_split = pd.read_csv(\"prices-split-adjusted.csv\")\n","\n","print(\"Prices-split-adjusted dataset:\")\n","print(prices_split.head(), \"\\n\")\n","\n","# Check for missing values\n","print(\"\\nMissing values in prices-split-adjusted:\\n\", prices_split.isnull().sum())\n"],"metadata":{"id":"jHQTZ-kiTcJ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prices_split.head()"],"metadata":{"id":"4vrr3u-9gX5S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 6))\n","prices_split.groupby('date')['close'].mean().plot(title=\"Average Closing Prices Over Time\")\n","plt.ylabel(\"Average Closing Price\")\n","plt.xlabel(\"Date\")\n","plt.xticks(rotation=45)\n","plt.show()"],"metadata":{"id":"CipXkyZFf-zf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## TODO: select the AAPL stock prices dataset, Filter a single stock for simplicity, e.g., 'AAPL'\n","stock_data =\n","print(\"\\nApple (AAPL) stock data:\")\n","print(stock_data.head())\n","\n","# Convert dates to datetime format and sort\n","stock_data['date'] = pd.to_datetime(stock_data['date'])\n","stock_data = stock_data.sort_values(by='date')\n","\n","stock_data['previous_close'] = stock_data['close'].shift(1)\n","stock_data['next_close'] = stock_data['close'].shift(-1)\n","\n","# Drop rows with NaN values (from lagging/leading)\n","stock_data = stock_data.dropna()"],"metadata":{"id":"VEHKkn4kgEK4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","X = stock_data[['previous_close']]  # Feature\n","y = stock_data['next_close']       # Target variable\n","\n","## TODO: Split the data into training and testing sets\n"],"metadata":{"id":"y0N8vWY6gHFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## TODO: Train Linear Regression Model\n","\n","\n","\n","# Predict on the test set\n","y_pred = model.predict(X_test)\n"],"metadata":{"id":"cMEQ0gHlTg7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(\"\\nModel Evaluation:\")\n","print(f\"Mean Squared Error: {mse:.2f}\")\n","print(f\"R-squared: {r2:.2f}\")"],"metadata":{"id":"FvRtjKKITtxj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot predictions vs actual values\n","plt.figure(figsize=(8, 6))\n","plt.scatter(y_test, y_pred, alpha=0.6, color='b')\n","plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', lw=2)  # Perfect prediction line\n","plt.title(\"Actual vs Predicted Stock Prices\")\n","plt.xlabel(\"Actual Prices\")\n","plt.ylabel(\"Predicted Prices\")\n","plt.show()\n","\n","# Step 6: Analyze model coefficients\n","print(\"\\nModel Coefficients:\")\n","print(f\"Intercept: {model.intercept_:.2f}\")\n","print(f\"Coefficient for 'previous_close': {model.coef_[0]:.2f}\")\n"],"metadata":{"id":"lHoflMFnmU61"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(14, 8))\n","\n","# Sort test data for smoother plotting\n","test_data = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}, index=X_test.index).sort_index()\n","\n","# Plot actual prices\n","plt.plot(test_data.index, test_data['Actual'], label='Actual Prices', color='blue', linewidth=2)\n","\n","# Plot predicted prices\n","plt.plot(test_data.index, test_data['Predicted'], label='Predicted Prices', color='orange', linestyle='--', linewidth=2)\n","\n","plt.title(\"Stock Price Prediction: Actual vs Predicted\", fontsize=16)\n","plt.xlabel(\"Index (sorted test set)\", fontsize=12)\n","plt.ylabel(\"Stock Price\", fontsize=12)\n","plt.legend(fontsize=12)\n","plt.grid(alpha=0.3)\n","\n","# Highlight differences\n","for i in range(len(test_data)):\n","    plt.plot([test_data.index[i], test_data.index[i]],\n","             [test_data['Actual'].iloc[i], test_data['Predicted'].iloc[i]],\n","             color='gray', alpha=0.4, linestyle='--')\n","\n","plt.show()"],"metadata":{"id":"fawHD0Lcg6xc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Logistic regression using a real-world dataset"],"metadata":{"id":"-DlrrHUgmq8I"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","import matplotlib.pyplot as plt\n","\n","# Load dataset\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n","data = pd.read_csv(url, header=None, names=columns)"],"metadata":{"id":"VF4zmFUams2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display the first few rows\n","print(\"Dataset preview:\")\n","print(data.head())\n","\n","# Check for missing values\n","print(\"\\nMissing values count:\")\n","print(data.isnull().sum())\n"],"metadata":{"id":"ddrlAfIxnJuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace zero values in specific columns with NaN (indicates missing values)\n","columns_to_replace = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n","for col in columns_to_replace:\n","    data[col].replace(0, np.nan, inplace=True)\n","\n","# Fill missing values with the column mean\n","data.fillna(data.mean(), inplace=True)\n","\n","# Split data into features and target\n","X = data.drop(columns='Outcome')\n","y = data['Outcome']"],"metadata":{"id":"S7b4VXcPnLI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## TODO: Normalize feature using a StandardScaler\n","from sklearn.preprocessing import StandardScaler\n","\n","## TODO: Split into training and testing sets\n","X_train, X_test, y_train, y_test =\n","\n","## TODO: Train Logistic Regression Model\n","\n","# Make predictions\n","y_pred ="],"metadata":{"id":"hr4tiGK3nNMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate model performance\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy:.2f}\")\n","\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n","\n","report = classification_report(y_test, y_pred)\n","print(\"\\nClassification Report:\")\n","print(report)"],"metadata":{"id":"6geDmtOCnfMN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implement SGD"],"metadata":{"id":"hjiIiHht7nlM"}},{"cell_type":"code","source":["# Sigmoid function\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","def sgd_logistic_regression(X, y, learning_rate=0.1, epochs=10, batch_size=32):\n","    np.random.seed(42)\n","    n_samples, n_features = X.shape\n","\n","    ##TODO: randomly initialize weights\n","    weights =\n","    bias = 0\n","\n","    for epoch in range(epochs):\n","        # Shuffle the data\n","        indices = np.arange(n_samples)\n","        np.random.shuffle(indices)\n","        X, y = X[indices], y[indices]\n","\n","        for start in range(0, n_samples, batch_size):\n","            end = start + batch_size\n","            X_batch, y_batch = X[start:end], y[start:end]\n","\n","            # TODO: run linear model with sigmoid\n","            linear_model =\n","            y_pred =\n","\n","            # TODO: Gradients\n","            error =\n","            dw =\n","            db =\n","\n","             # TODO: update weights\n","            weights -=\n","            bias -=\n","\n","        # TODO: get predictions and loss\n","        y_preds =\n","        loss =\n","        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}')\n","\n","    return weights, bias\n"],"metadata":{"id":"UwRpOkLX7qAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = data.drop(columns='Outcome')\n","y = data['Outcome']\n","\n","# Standardize features\n","X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n","\n","# TODO: Split data into train and test sets\n","X_train, X_test, y_train, y_test =\n","\n","# Train logistic regression model using SGD\n","weights, bias = sgd_logistic_regression(X_train.values, y_train.values, learning_rate=0.2, epochs=10)\n"],"metadata":{"id":"S3MRZVOR8Aul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# TODO: Make predictions on the test set\n","y_test_pred =\n","y_test_pred_class =\n","\n","# Evaluate model\n","accuracy = accuracy_score(y_test, y_test_pred_class)\n","print(f'Accuracy: {accuracy:.4f}')\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_test, y_test_pred_class))\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_test_pred_class))"],"metadata":{"id":"rnGmKuyk8JDf"},"execution_count":null,"outputs":[]}]}